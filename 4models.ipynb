{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.884</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.807</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.641</td>\n",
       "      <td>86.049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.545</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.809</td>\n",
       "      <td>91.967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.489</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.341</td>\n",
       "      <td>117.431</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.539</td>\n",
       "      <td>0.931</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.803</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.685</td>\n",
       "      <td>85.571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.734</td>\n",
       "      <td>11</td>\n",
       "      <td>-2.832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.608</td>\n",
       "      <td>97.044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.545   0.884    5    -4.807     0        0.367      0.290000   \n",
       "1         0.795   0.545    7    -8.153     1        0.343      0.003960   \n",
       "2         0.489   0.871    5    -5.825     1        0.386      0.002850   \n",
       "3         0.539   0.931    4    -1.803     0        0.262      0.000713   \n",
       "4         0.918   0.734   11    -2.832     0        0.269      0.029400   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  Label  \n",
       "0          0.000000     0.370    0.641   86.049      1  \n",
       "1          0.000000     0.273    0.809   91.967      1  \n",
       "2          0.000004     0.130    0.341  117.431      1  \n",
       "3          0.000000     0.204    0.685   85.571      0  \n",
       "4          0.000008     0.191    0.608   97.044      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"project_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ta bort punkter som är orimliga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = df[df['energy'] == 734].index[0]\n",
    "idx2 = df[df['loudness'] == -6542].index[0]\n",
    "\n",
    "df.drop(index = [idx1, idx2], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dela data på träning och test\n",
    "Tar med alla features. Splittar på test och träningsdata. Scala data så att logistic regression inte klagar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Label\"]\n",
    "# variables = [\"energy\", \"loudness\", \"valence\", \"tempo\",\"acousticness\", \"instrumentalness\"] #, 'liveness', 'valence', 'tempo']\n",
    "X = df.drop([\"Label\"], axis=1) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the training data and save the transform\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skapa och fitta modellerna\n",
    "visa resultat på träningsdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  81.55\n",
      "Gaussian Naive Bayes:  71.13\n",
      "Decision Tree Classifier:  100.0\n",
      "K Nearest Neighbors:  89.29\n",
      "Random forest classifier 100.0\n",
      "Multi-layer Perceptron 99.7\n",
      "LDA 82.14\n",
      "QDA 86.61\n",
      "Support vector machine 89.58\n",
      "Bagging 98.81\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train_scaled,y_train)\n",
    "log_result_train = round(log.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train_scaled,y_train)\n",
    "NB_result_train = round(NB.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train_scaled,y_train)\n",
    "DT_result_train = round(DT.score(X_train_scaled,y_train)*100, 2)\n",
    "\n",
    "# K Nearest Neighbors\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_train_scaled,y_train)\n",
    "KNN_result_train = round(KNN.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "# Random forest classifier\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train_scaled,y_train)\n",
    "RF_result_train = round(RF.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "# Multi-layer Perceptron (NN)\n",
    "MLP = MLPClassifier(max_iter=2000)\n",
    "MLP.fit(X_train_scaled,y_train)\n",
    "MLP_result_train = round(MLP.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "\n",
    "# LDA\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(X_train_scaled,y_train)\n",
    "LDA_result_train = round(LDA.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "# QDA\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "QDA.fit(X_train_scaled,y_train)\n",
    "QDA_result_train = round(QDA.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "# Support vector machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train_scaled,y_train)\n",
    "svm_result_train = round(svm.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "# Bagging\n",
    "bag = BaggingClassifier()\n",
    "bag.fit(X_train_scaled,y_train)\n",
    "bag_result_train = round(bag.score(X_train_scaled,y_train)*100,2)\n",
    "\n",
    "\n",
    "print('Logistic Regression: ', log_result_train)\n",
    "print('Gaussian Naive Bayes: ', NB_result_train)\n",
    "print('Decision Tree Classifier: ', DT_result_train)\n",
    "print('K Nearest Neighbors: ', KNN_result_train)\n",
    "print('Random forest classifier', RF_result_train)\n",
    "print('Multi-layer Perceptron', MLP_result_train)\n",
    "print('LDA', LDA_result_train)\n",
    "print('QDA', QDA_result_train)\n",
    "print('Support vector machine', svm_result_train)\n",
    "print('Bagging', bag_result_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testa modellerna på testdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Logistic Regression Score: 80.69\n",
      "1. Logistic Regression Accuracy Score: 80.69\n",
      "2. Gaussian Naive Bayes Score: 68.97\n",
      "2. Gaussian Naive Bayes Accuracy Score: 68.97\n",
      "3. Decision Tree Score: 77.24\n",
      "3. Decision Tree Accuracy Score: 77.24\n",
      "4. K-NN Score: 77.93\n",
      "4. K-NN Accuracy Score: 77.93\n",
      "5. Random forest Classifier Score: 80.69\n",
      "5. Random forest Classifier Accuracy Score: 80.69\n",
      "6. Multi-layer Perceptron Score: 81.38\n",
      "6. Multi-layer Perceptron Accuracy Score: 81.38\n",
      "7. LDA Score: 81.38\n",
      "7. LDA Accuracy Score: 81.38\n",
      "8. QDA Score: 76.55\n",
      "8. QDA Accuracy Score: 76.55\n",
      "9. Support vector machine Score: 80.69\n",
      "9. Support vector machine Accuracy Score: 80.69\n",
      "10. Bagging Score: 79.31\n",
      "10. Bagging Accuracy Score: 79.31\n"
     ]
    }
   ],
   "source": [
    "#Score\n",
    "log_result_test = round(log.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "NB_result_test = round(NB.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "DT_result_test = round(DT.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "KNN_result_test = round(KNN.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "RF_result_test = round(RF.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "MLP_result_test = round(MLP.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "LDA_result_test = round(LDA.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "QDA_result_test = round(QDA.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "svm_result_test = round(svm.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "bag_result_test = round(bag.score(X_test_scaled,y_test)*100,2)\n",
    "\n",
    "#Accuracy score\n",
    "log_result_test_ac = round(accuracy_score(y_test,log.predict(X_test_scaled))*100,2)\n",
    "\n",
    "NB_result_test_ac = round(accuracy_score(y_test,NB.predict(X_test_scaled))*100,2)\n",
    "\n",
    "DT_result_test_ac = round(accuracy_score(y_test,DT.predict(X_test_scaled))*100,2)\n",
    "\n",
    "KNN_result_test_ac = round(accuracy_score(y_test,KNN.predict(X_test_scaled))*100,2)\n",
    "\n",
    "RF_result_test_ac = round(accuracy_score(y_test,RF.predict(X_test_scaled))*100,2)\n",
    "\n",
    "MLP_result_test_ac = round(accuracy_score(y_test,MLP.predict(X_test_scaled))*100,2)\n",
    "\n",
    "LDA_result_test_ac = round(accuracy_score(y_test,LDA.predict(X_test_scaled))*100,2)\n",
    "\n",
    "QDA_result_test_ac = round(accuracy_score(y_test,QDA.predict(X_test_scaled))*100,2)\n",
    "\n",
    "svm_result_test_ac = round(accuracy_score(y_test,svm.predict(X_test_scaled))*100,2)\n",
    "\n",
    "bag_result_test_ac = round(accuracy_score(y_test,bag.predict(X_test_scaled))*100,2)\n",
    "\n",
    "\n",
    "print('1. Logistic Regression Score: {}'.format(log_result_test))\n",
    "print('1. Logistic Regression Accuracy Score: {}'.format(log_result_test_ac))\n",
    "print('2. Gaussian Naive Bayes Score: {}'.format(NB_result_test))\n",
    "print('2. Gaussian Naive Bayes Accuracy Score: {}'.format(NB_result_test_ac))\n",
    "print('3. Decision Tree Score: {}'.format(DT_result_test))\n",
    "print('3. Decision Tree Accuracy Score: {}'.format(DT_result_test_ac))\n",
    "print('4. K-NN Score: {}'.format(KNN_result_test))\n",
    "print('4. K-NN Accuracy Score: {}'.format(KNN_result_test_ac))\n",
    "print('5. Random forest Classifier Score: {}'.format(RF_result_test))\n",
    "print('5. Random forest Classifier Accuracy Score: {}'.format(RF_result_test_ac))\n",
    "print('6. Multi-layer Perceptron Score: {}'.format(MLP_result_test))\n",
    "print('6. Multi-layer Perceptron Accuracy Score: {}'.format(MLP_result_test_ac))\n",
    "print('7. LDA Score: {}'.format(LDA_result_test))\n",
    "print('7. LDA Accuracy Score: {}'.format(LDA_result_test_ac))\n",
    "print('8. QDA Score: {}'.format(QDA_result_test))\n",
    "print('8. QDA Accuracy Score: {}'.format(QDA_result_test_ac))\n",
    "print('9. Support vector machine Score: {}'.format(svm_result_test))\n",
    "print('9. Support vector machine Accuracy Score: {}'.format(svm_result_test_ac))\n",
    "print('10. Bagging Score: {}'.format(bag_result_test))\n",
    "print('10. Bagging Accuracy Score: {}'.format(bag_result_test_ac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning of hyperparameters? CV and or ROC?\n",
    "Receiver operating characteristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA tuned, training: 82.14\n",
      "LDA tuned, test: 81.38\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "LDA_t = LinearDiscriminantAnalysis()\n",
    "LDA_t.fit(X_train,y_train)\n",
    "LDA_t_result_train = round(LDA_t.score(X_train,y_train)*100,2)\n",
    "print('LDA tuned, training:', LDA_t_result_train)\n",
    "\n",
    "LDA_t_result_test = round(LDA_t.score(X_test,y_test)*100,2)\n",
    "print('LDA tuned, test: {}'.format(LDA_t_result_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, score: 84.83\n",
      "Test score: 78.62\n",
      "Bagging tuned, test_final check: 84.83\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "import pickle\n",
    "import os.path\n",
    "if os.path.isfile('bag_model.sav'):\n",
    "    bag = pickle.load(open('bag_model.sav', 'rb'))\n",
    "    bag_result_test_old = round(bag.score(X_test_scaled,y_test)*100,2)\n",
    "    print('File exists, score: {}' .format(bag_result_test_old))\n",
    "else:\n",
    "    bag_result_test_old = 0\n",
    "    \n",
    "\n",
    "bagC = BaggingClassifier(n_jobs = -1)\n",
    "param_grid = [\n",
    "        {\n",
    "            'bootstrap_features' : [True, False],\n",
    "            'bootstrap' : [True, False],\n",
    "            'max_features': [1,2,3,4],\n",
    "            'n_estimators': [\n",
    "              100,120,140\n",
    "             ]\n",
    "        }\n",
    "       ]\n",
    "for i in range(1):\n",
    "    bag = GridSearchCV(bagC, param_grid, cv=5,\n",
    "                           scoring='accuracy')\n",
    "    bag.fit(X_train_scaled,y_train)\n",
    "    bag_result_test = round(bag.score(X_test_scaled,y_test)*100,2)\n",
    "    print('Test score: {}' .format(bag_result_test))\n",
    "    if bag_result_test > bag_result_test_old:\n",
    "        bag_result_test_old = bag_result_test\n",
    "        print('Bagging tuned, test: {}'.format(bag_result_test))\n",
    "        pickle.dump(bag, open('bag_model.sav', 'wb'))\n",
    "        print('File saved')\n",
    "\n",
    "bag_BEST = pickle.load(open('bag_model.sav', 'rb'))\n",
    "bag_result_test_final = round(bag_BEST.score(X_test_scaled,y_test)*100,2)\n",
    "print('Bagging tuned, test_final check: {}'.format(bag_result_test_final))\n",
    "#bag_BEST.get_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron (NN)\n",
    "import pickle\n",
    "import os.path\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "if os.path.isfile('MLP_model.sav'):\n",
    "    MLP = pickle.load(open('MLP_model.sav', 'rb'))\n",
    "    MLP_result_test_old = round(MLP.score(X_test_scaled,y_test)*100,2)\n",
    "    print('File exists')\n",
    "else:\n",
    "    MLP_result_test_old = 0\n",
    "MLPC = MLPClassifier(max_iter = 3000)\n",
    "param_grid = [\n",
    "        {\n",
    "            'activation' : ['logistic', 'relu'],\n",
    "            'solver' : ['lbfgs', 'adam'],\n",
    "            'hidden_layer_sizes': [\n",
    "              (10,),(20,),(30,)\n",
    "             ]\n",
    "        }\n",
    "       ]\n",
    "\n",
    "for i in range(1):\n",
    "    MLP = GridSearchCV(MLPC, param_grid, cv=5,\n",
    "                           scoring='accuracy')\n",
    "    MLP.fit(X_train_scaled,y_train)\n",
    "    MLP_result_test = round(MLP.score(X_test_scaled,y_test)*100,2)\n",
    "    if MLP_result_test > MLP_result_test_old:\n",
    "        MLP_result_test_old = MLP_result_test\n",
    "        print('MLP tuned, test: {}'.format(MLP_result_test))\n",
    "        pickle.dump(MLP, open('MLP_model.sav', 'wb'))\n",
    "        print ('File saved')\n",
    "\n",
    "MLP_BEST = pickle.load(open('MLP_model.sav', 'rb'))\n",
    "MLP_result_test_final = round(MLP_BEST.score(X_test_scaled,y_test)*100,2)\n",
    "print('MLP tuned, test_final check: {}'.format(MLP_result_test_final))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"project_train.csv\")\n",
    "idx1 = df[df['energy'] == 734].index[0]\n",
    "idx2 = df[df['loudness'] == -6542].index[0]\n",
    "\n",
    "df.drop(index = [idx1, idx2], inplace = True)\n",
    "y = df[\"Label\"]\n",
    "# variables = [\"energy\", \"loudness\", \"valence\", \"tempo\",\"acousticness\", \"instrumentalness\"] #, 'liveness', 'valence', 'tempo']\n",
    "X = df.drop([\"Label\"], axis=1) \n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Scale the training data and save the transform\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    MLP_result_test_final = round(MLP_BEST.score(X_test_scaled,y_test)*100,2)\n",
    "    print('MLP tuned, test_final check: {}'.format(MLP_result_test_final))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag Score: 67.5\n",
      "[0 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0\n",
      " 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1\n",
      " 0 1 0 0 1 0]\n",
      "54\n",
      "81\n",
      "lower=0.564, upper=0.769\n",
      "log Score: 67.5\n",
      "SVM Score: 66.25\n"
     ]
    }
   ],
   "source": [
    "# Prediction with the best models\n",
    "\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "bag = pickle.load(open('bag_model.sav', 'rb'))\n",
    "\n",
    "df = pd.read_csv(\"project_test.csv\")\n",
    "\n",
    "\n",
    "Y = df[\"Label\"]\n",
    "# variables = [\"energy\", \"loudness\", \"valence\", \"tempo\",\"acousticness\", \"instrumentalness\"] #, 'liveness', 'valence', 'tempo']\n",
    "X = df.drop([\"Label\"], axis=1) \n",
    "\n",
    "# Scale the training data and save the transform\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "Score = round(bag.score(X,Y)*100,2)\n",
    "Predict = bag.predict(X)\n",
    "print ('Bag Score: {}'.format(Score))\n",
    "print (Predict)\n",
    "\n",
    "N_correct = accuracy_score(Y,Predict,normalize=False)\n",
    "print(N_correct)\n",
    "N  = 81\n",
    "print(N)\n",
    "lower, upper = proportion_confint(N_correct, N, 0.05)\n",
    "print('lower=%.3f, upper=%.3f' % (lower, upper))\n",
    "\n",
    "\n",
    "Score = round(log.score(X,Y)*100,2)\n",
    "print ('log Score: {}'.format(Score))\n",
    "\n",
    "Score = round(svm.score(X,Y)*100,2)\n",
    "print ('SVM Score: {}'.format(Score))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
